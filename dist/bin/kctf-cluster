#!/bin/bash
# Copyright 2020 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
set -Eeuo pipefail

source "${KCTF_BIN}/kctf-log"

function create_operator {
  # Creating CRD, rbac and operator
  kubectl apply -f "${KCTF_CTF_DIR}/kctf/resources/kctf.dev_challenges_crd.yaml"
  kubectl apply -f "${KCTF_CTF_DIR}/kctf/resources/rbac.yaml"
  kubectl apply -f "${KCTF_CTF_DIR}/kctf/resources/operator.yaml"

  OPERATOR_IMAGE=$("${KCTF_BIN}/yq" eval '.spec.template.spec.containers[0].image' "${KCTF_CTF_DIR}/kctf/resources/operator.yaml")

  # The operator needs to create some subresources, e.g. the gcsfuse service account
  for i in {1..100}; do
    kubectl get pods --namespace kctf-system -o=jsonpath="{.items[?(@.spec.containers[0].image==\"${OPERATOR_IMAGE}\")].status.containerStatuses[0].ready}" | grep "true" && break
    if [ "$i" == "100" ]; then
      _kctf_log_err "Couldn't find a kctf-operator pod with status ready=true and image=\"${OPERATOR_IMAGE}\" after 5 minutes"
      kubectl get pods --namespace kctf-system -o=yaml >&2
      exit 1
    fi
    sleep 3
  done
}

function kctf_cluster_start_gce {
  MIN_NODES="1"
  MAX_NODES="2"
  NUM_NODES="1"
  MACHINE_TYPE="n2-standard-4"

  EXISTING_CLUSTER=$(gcloud container clusters list --filter "name=${CLUSTER_NAME}" --format 'get(name)')

  if [ -z "${EXISTING_CLUSTER}" ]; then
    gcloud container clusters create --release-channel=regular --enable-network-policy --enable-autoscaling --min-nodes ${MIN_NODES} --max-nodes ${MAX_NODES} --num-nodes ${NUM_NODES} --create-subnetwork name=kctf-${CLUSTER_NAME}-subnet --no-enable-master-authorized-networks --enable-ip-alias --enable-private-nodes --master-ipv4-cidr 172.16.0.32/28 --enable-autorepair --preemptible --machine-type ${MACHINE_TYPE} --workload-pool=${PROJECT}.svc.id.goog ${CLUSTER_NAME}
  fi

  EXISTING_ROUTER=$(gcloud compute routers list --filter "name=kctf-${CLUSTER_NAME}-nat-router" --format 'get(name)')
  if [ -z "${EXISTING_ROUTER}" ]; then
    gcloud compute routers create "kctf-${CLUSTER_NAME}-nat-router" --network=default --region "${ZONE::-2}"
  fi

  EXISTING_NAT=$(gcloud compute routers nats list --router "kctf-${CLUSTER_NAME}-nat-router" --router-region "${ZONE::-2}" --format 'get(name)')
  if [ -z "${EXISTING_NAT}" ]; then
    gcloud compute routers nats create "kctf-${CLUSTER_NAME}-nat-config" --router-region "${ZONE::-2}" --router kctf-${CLUSTER_NAME}-nat-router --nat-all-subnet-ip-ranges --auto-allocate-nat-external-ips
  fi

  kubectl create namespace "kctf-system" --dry-run=client -oyaml | kubectl apply -f - >&2

  # GCSFUSE

  SUFFIX=$(echo "${PROJECT}-${CLUSTER_NAME}-${ZONE}" | sha1sum)
  BUCKET_NAME="kctf-gcsfuse-${SUFFIX:0:16}"
  GCS_GSA_NAME="${BUCKET_NAME}"
  GCS_GSA_EMAIL=$(gcloud iam service-accounts list --filter "email=${GCS_GSA_NAME}@${PROJECT}.iam.gserviceaccount.com" --format 'get(email)' || true)

  if [ -z "${GCS_GSA_EMAIL}" ]; then
    gcloud iam service-accounts create "${GCS_GSA_NAME}" --description "kCTF GCSFUSE service account ${CLUSTER_NAME} ${ZONE}" --display-name "kCTF GCSFUSE ${CLUSTER_NAME} ${ZONE}"
    GCS_GSA_EMAIL=$(gcloud iam service-accounts list --filter "email=${GCS_GSA_NAME}@${PROJECT}.iam.gserviceaccount.com" --format 'get(email)')
    while [ -z "${GCS_GSA_EMAIL}" ]; do
      sleep 1
      GCS_GSA_EMAIL=$(gcloud iam service-accounts list --filter "email=${GCS_GSA_NAME}@${PROJECT}.iam.gserviceaccount.com" --format 'get(email)')
    done
  fi

  create_operator

  GCS_KSA_NAME="gcsfuse-sa"

  gcloud iam service-accounts add-iam-policy-binding --role roles/iam.workloadIdentityUser --member "serviceAccount:${PROJECT}.svc.id.goog[kctf-system/${GCS_KSA_NAME}]" ${GCS_GSA_EMAIL}
  kubectl annotate serviceaccount --namespace kctf-system ${GCS_KSA_NAME} iam.gke.io/gcp-service-account=${GCS_GSA_EMAIL} --overwrite

  if ! gsutil du "gs://${BUCKET_NAME}/"; then
    gsutil mb -l eu "gs://${BUCKET_NAME}/"
  fi

  if gsutil uniformbucketlevelaccess get "gs://${BUCKET_NAME}" | grep -q "Enabled: True"; then
    gsutil iam ch "serviceAccount:${GCS_GSA_EMAIL}:roles/storage.legacyBucketOwner" "gs://${BUCKET_NAME}"
    gsutil iam ch "serviceAccount:${GCS_GSA_EMAIL}:roles/storage.legacyObjectOwner" "gs://${BUCKET_NAME}"
  else
    gsutil acl ch -u "${GCS_GSA_EMAIL}:O" "gs://${BUCKET_NAME}"
  fi

  kubectl create configmap gcsfuse-config --from-literal=gcs_bucket="${BUCKET_NAME}" --namespace kctf-system --dry-run=client -o yaml | kubectl apply -f -

  kubectl patch ServiceAccount default --patch "automountServiceAccountToken: false"

  # Cloud DNS

  if [ ! -z "${DOMAIN_NAME}" ]
  then
    DNS_ZONE=$(gcloud dns managed-zones list --filter "dns_name:${DOMAIN_NAME}" --format 'get(name)')
    if [ -z "${DNS_ZONE}" ]; then
      gcloud dns managed-zones create "${CLUSTER_NAME}-dns-zone" --description "DNS Zone for ${DOMAIN_NAME}" --dns-name="${DOMAIN_NAME}."
    fi

    DNS_GSA_NAME="kctf-cloud-dns"
    DNS_GSA_EMAIL=$(gcloud iam service-accounts list --filter "email=${DNS_GSA_NAME}@${PROJECT}.iam.gserviceaccount.com" --format 'get(email)' || true)

    if [ -z "${DNS_GSA_EMAIL}" ]; then
      gcloud iam service-accounts create "${DNS_GSA_NAME}" --description "kCTF Cloud DNS service account ${CLUSTER_NAME} ${ZONE}" --display-name "kCTF Cloud DNS ${CLUSTER_NAME} ${ZONE}"
      DNS_GSA_EMAIL=$(gcloud iam service-accounts list --filter "email=${DNS_GSA_NAME}@${PROJECT}.iam.gserviceaccount.com" --format 'get(email)')
      while [ -z "${DNS_GSA_EMAIL}" ]; do
        sleep 1
        DNS_GSA_EMAIL=$(gcloud iam service-accounts list --filter "email=${DNS_GSA_NAME}@${PROJECT}.iam.gserviceaccount.com" --format 'get(email)')
      done
    fi

    DNS_KSA_NAME="external-dns-sa"

    gcloud iam service-accounts add-iam-policy-binding --role roles/iam.workloadIdentityUser --member "serviceAccount:${PROJECT}.svc.id.goog[kctf-system/${DNS_KSA_NAME}]" ${DNS_GSA_EMAIL}
    kubectl annotate serviceaccount --namespace kctf-system ${DNS_KSA_NAME} iam.gke.io/gcp-service-account=${DNS_GSA_EMAIL} --overwrite

    gcloud projects add-iam-policy-binding ${PROJECT} --member=serviceAccount:${DNS_GSA_EMAIL} --role=roles/dns.admin

    kubectl create configmap --namespace kctf-system external-dns --from-literal=DOMAIN_NAME=${DOMAIN_NAME} --from-literal=EMAIL_ADDRESS=${EMAIL_ADDRESS:-} --dry-run=client -o yaml | kubectl apply -f -
  fi
}

function kctf_cluster_start {
  case "${CLUSTER_TYPE}" in
    gce)
      kctf_cluster_start_gce
      return
      ;;
    kind)
      kctf_cluster_start_kind
      return
      ;;
    *)
      _kctf_log_err "unknown cluster type \"${CLUSTER_TYPE}\""
      return 1
      ;;
  esac
}

function kctf_cluster_stop_gce {
  _kctf_log "deleting all challenges so that load balancers etc can be cleaned up"
  CHALLENGES=$(kubectl get challenge --all-namespaces -o=jsonpath='{range .items[*]}{@.metadata.namespace}{"/"}{@.metadata.name}{" "}{end}')
  if [[ ! -z "${CHALLENGES}" ]]; then
    for chal_and_ns in ${CHALLENGES}; do
      IFS='/' read -r -a chal_and_ns_array <<< "$chal_and_ns"
      chal_namespace="${chal_and_ns_array[0]}"
      chal_name="${chal_and_ns_array[1]}"
      kubectl delete "challenge/${chal_name}" --namespace "${chal_namespace}"
    done
  fi

  # deleting the cluster below takes a while, so sleeping for a bit doesn't hurt
  _kctf_log "Sleeping 20s to give time to delete resources"
  sleep 20

  CLOUDSDK_CORE_DISABLE_PROMPTS=1 gcloud container clusters delete ${CLUSTER_NAME}
  gcloud compute routers delete "kctf-${CLUSTER_NAME}-nat-router" --region "${ZONE::-2}" --quiet

  SUFFIX=$(echo "${PROJECT}-${CLUSTER_NAME}-${ZONE}" | sha1sum)
  GSA_NAME="kctf-gcsfuse-${SUFFIX:0:16}"
  GSA_EMAIL=$(gcloud iam service-accounts list --filter "email=${GSA_NAME}@${PROJECT}.iam.gserviceaccount.com" --format 'get(email)' || true)
  if [ -z "${GSA_EMAIL}" ]; then
    gcloud iam service-accounts delete "${GSA_EMAIL}"
  fi
}

function kctf_cluster_start_kind {
  if ! "${KCTF_BIN}/kind" get kubeconfig --name "${CLUSTER_NAME}" >/dev/null 2>/dev/null; then
    "${KCTF_BIN}/kind" create cluster --name "${CLUSTER_NAME}"
  fi

  kubectl create namespace "kctf-system" --dry-run=client -oyaml | kubectl apply -f - >&2

  create_operator

  kubectl patch ServiceAccount default --patch "automountServiceAccountToken: false"
}

function kctf_cluster_stop_kind {
  "${KCTF_BIN}/kind" delete cluster --name "${CLUSTER_NAME}"
}

function kctf_cluster_stop {
  case "${CLUSTER_TYPE}" in
    gce)
      kctf_cluster_stop_gce
      return
      ;;
    kind)
      kctf_cluster_stop_kind
      return
      ;;
    *)
      _kctf_log_err "unknown cluster type \"${CLUSTER_TYPE}\""
      return 1
      ;;
  esac
}

function kctf_cluster_resize_usage {
  echo -e "usage: kctf cluster resize [args]" >&2
  echo -e "args:" >&2
  echo -e "  -h|--help      print this help" >&2
  echo -e "  --machine-type machine type to use" >&2
  echo -e "                 to list available types, run: gcloud compute machine-types list --zones=\"${ZONE}\"" >&2
  echo -e "  --min-nodes    (required) minimum number of nodes in the cluster" >&2
  echo -e "  --max-nodes    (required) maximum number of nodes in the cluster" >&2
  echo -e "  --num-nodes    (required) initial number of nodes in the cluster" >&2
  echo -e "  --pool-name    name of the node pool" >&2
  echo -e "  --old-pool     name of the old pool to replace" >&2
}

function kctf_cluster_resize {
  if [[ "${CLUSTER_TYPE}" != "gce" ]]; then
    _kctf_log_err "only cluster type \"gce\" is supported by resize"
    return 1
  fi

  OPTS="h"
  LONGOPTS="help,machine-type:,min-nodes:,max-nodes:,num-nodes:,pool-name:,old-pool"
  PARSED=$(getopt --options=$OPTS --longoptions=$LONGOPTS --name "kctf chal create" -- "$@")
  if [[ $? -ne 0 ]]; then
    kctf_cluster_resize_usage
    exit 1
  fi
  eval set -- "$PARSED"

  MACHINE_TYPE="n2-standard-4"
  MIN_NODES=
  MAX_NODES=
  NUM_NODES=
  NEW_POOL_NAME=
  OLD_POOL_NAME=
  while true; do
    case "$1" in
      -h|--help)
        kctf_cluster_resize_usage
        exit 0
        ;;
      --machine-type)
        MACHINE_TYPE="$2"
        shift 2
        ;;
      --min-nodes)
        MIN_NODES="$2"
        shift 2
        ;;
      --max-nodes)
        MAX_NODES="$2"
        shift 2
        ;;
      --num-nodes)
        NUM_NODES="$2"
        shift 2
        ;;
      --pool-name)
        NEW_POOL_NAME="$2"
        shift 2
        ;;
      --old-pool)
        OLD_POOL_NAME="$2"
        shift 2
        ;;
      --)
        shift
        break
        ;;
      *)
        _kctf_log_err "Unrecognized argument \"$1\"."
        kctf_cluster_resize_usage
        exit 1
        ;;
    esac
  done

  if [[ -z "${MIN_NODES}" ]] || [[ -z "${MAX_NODES}" ]] || [[ -z "${NUM_NODES}" ]]; then
    _kctf_log_err "Required arguments missing"
    kctf_cluster_resize_usage
    exit 1
  fi

  if [[ -z "${OLD_POOL_NAME}" ]]; then
    OLD_POOL_NAME=$(gcloud container node-pools list --cluster ${CLUSTER_NAME} --format 'value(name)')
    if [ $(echo "${OLD_POOL_NAME}" | wc -l) != "1" ]; then
      _kctf_log_err 'Multiple node pools found. Please choose which to replace with --old-pool.'
      echo '== node pools ==' >&2
      echo "${OLD_POOL_NAME}" >&2
      exit 1
    fi
  fi

  if [[ -z "${NEW_POOL_NAME}" ]]; then
    NEW_POOL_NAME="${OLD_POOL_NAME}-resized"
  fi

  if [ "${OLD_POOL_NAME}" = "${NEW_POOL_NAME}" ]; then
    _kctf_log_err "New pool can't have the same name as the old pool."
    exit 1
  fi

  if [[ $# -ne 0 ]]; then
    _kctf_log_err "Unrecognized arguments \"$@\"."
    kctf_cluster_resize_usage
    exit 1
  fi

  _kctf_log 'Creating the new node pool'
  gcloud container node-pools create "${NEW_POOL_NAME}" \
    --cluster="${CLUSTER_NAME}" \
    --machine-type="${MACHINE_TYPE}" \
    --enable-autorepair \
    --enable-autoupgrade \
    --num-nodes="${NUM_NODES}" \
    --enable-autoscaling \
    --min-nodes="${MIN_NODES}" \
    --max-nodes="${MAX_NODES}"

  _kctf_log 'Cordoning old nodes'
  for node in $(kubectl get nodes -l cloud.google.com/gke-nodepool="${OLD_POOL_NAME}" -o=name); do
    kubectl cordon "$node"
  done

  _kctf_log 'Draining old nodes'
  for node in $(kubectl get nodes -l cloud.google.com/gke-nodepool="${OLD_POOL_NAME}" -o=name); do
    kubectl drain --force --ignore-daemonsets --delete-local-data --grace-period=10 "$node";
  done

  _kctf_log "Deleting old node pool \"${OLD_POOL_NAME}\""
  gcloud container node-pools delete "${OLD_POOL_NAME}" --cluster "${CLUSTER_NAME}"
}

function kctf_cluster_usage {
  echo -e "usage: kctf cluster command" >&2
  echo -e "available commands:" >&2
  echo -e "  start:  start the cluster" >&2
  echo -e "  stop:   stop the cluster" >&2
  echo -e "  resize: resize the cluster" >&2
}

if [[ $# -lt 1 ]]; then
  _kctf_log_err "unexpected argument count"
  kctf_cluster_usage
  exit 1
fi

if [[ -z "${CLUSTER_NAME-}" ]]; then
  _kctf_log_err "No config loaded. You need to run \"kctf config\" first."
  exit 1
fi

case "$1" in
  -h|--help)
    kctf_cluster_usage
    exit 0
    ;;
  start)
    shift
    kctf_cluster_start $@
    ;;
  stop)
    shift
    kctf_cluster_stop $@
    ;;
  resize)
    shift
    kctf_cluster_resize $@
    ;;
  *)
    _kctf_log_err "unknown command"
    kctf_cluster_usage
    exit 1
    ;;
esac

